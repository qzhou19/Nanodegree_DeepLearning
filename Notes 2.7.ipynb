{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Keras Project (IMAGE): Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Flow:\n",
    "\n",
    "1. Download/Load Pre-trained models and data\n",
    "2. Build CNN model from data directly\n",
    "3. Transfer Learning with VGG16\n",
    "4. Transfer Learning with Xception\n",
    "5. Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline      \n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True      \n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "data_path='../ClassSampleData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained model\n",
    "# Human detector\n",
    "face_cascade = cv2.CascadeClassifier(data_path+'haarcascade_frontalface_alt.xml')\n",
    "# Dog detector\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0\n",
    "\n",
    "# convert image to 4D tensor (obs, row, column, channels) for dog_detector\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "def dog_detector(img_path):\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    prediction = np.argmax(ResNet50_model.predict(img))\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Dog data\n",
    "train_files, train_targets = load_dataset(data_path+'dogImages/train')\n",
    "valid_files, valid_targets = load_dataset(data_path+'dogImages/valid')\n",
    "test_files, test_targets = load_dataset(data_path+'dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[30:-1] for item in sorted(glob(data_path+\"dogImages/train/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6680/6680 [00:41<00:00, 66.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 835/835 [00:10<00:00, 81.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 836/836 [00:08<00:00, 93.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Data\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 133)               8645      \n",
      "=================================================================\n",
      "Total params: 32,229\n",
      "Trainable params: 32,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A CNN Model use input directly\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding='valid', activation='relu', input_shape=train_tensors.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.86950, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.86950 to 4.83511, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.83511 to 4.78148, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.78148 to 4.76950, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.76950 to 4.70687, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.70687 to 4.70424, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.70424 to 4.66218, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.66218 to 4.62621, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.62621 to 4.60878, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.60878 to 4.59399, saving model to checkpoints/N2_7_weights.best.from_scratch.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209d418dac8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='checkpoints/N2_7_weights.best.from_scratch.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets), epochs=10, batch_size=20, callbacks=[checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 4.3062%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('checkpoints/N2_7_weights.best.from_scratch.hdf5')\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_5 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use transfer learning, load bottleneck features VGG16\n",
    "bottleneck_features = np.load('../ClassHelper/bottleneck_features/DogVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']\n",
    "\n",
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.35689, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.35689 to 9.84910, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.84910 to 9.41905, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.41905 to 9.13287, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 9.13287 to 9.05116, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 9.05116 to 8.88367, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 8.88367 to 8.88337, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 8.88337 to 8.66435, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 8.66435 to 8.26111, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 8.26111 to 8.09543, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 8.09543 to 7.98592, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 7.98592 to 7.94768, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.94768 to 7.79321, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.79321 to 7.67459, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.67459 to 7.66478, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 7.66478 to 7.58662, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.58662 to 7.53092, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.53092 to 7.49718, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.49718 to 7.41309, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 7.41309 to 7.25764, saving model to checkpoints/N2_7_weights.best.VGG16.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209da4089e8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoints/N2_7_weights.best.VGG16.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, validation_data=(valid_VGG16, valid_targets), epochs=20, batch_size=20, callbacks=[checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 47.1292%\n"
     ]
    }
   ],
   "source": [
    "VGG16_model.load_weights('checkpoints/N2_7_weights.best.VGG16.hdf5')\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 133)               34181     \n",
      "=================================================================\n",
      "Total params: 558,725\n",
      "Trainable params: 558,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# use transfer learning, load bottleneck features Xception\n",
    "bottleneck_features = np.load('../ClassHelper/bottleneck_features/DogXceptionData.npz')\n",
    "train_Xception = bottleneck_features['train']\n",
    "valid_Xception = bottleneck_features['valid']\n",
    "test_Xception = bottleneck_features['test']\n",
    "\n",
    "Xception_model = Sequential()\n",
    "Xception_model.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "Xception_model.add(Dense(256, activation='relu'))\n",
    "Xception_model.add(Dropout(rate=0.3))\n",
    "Xception_model.add(Dense(133, activation='softmax'))\n",
    "Xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52507, saving model to checkpoints/N2_7_weights.best.Xception.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52507 to 0.51640, saving model to checkpoints/N2_7_weights.best.Xception.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51640 to 0.51045, saving model to checkpoints/N2_7_weights.best.Xception.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51045\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.51045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209d41057b8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoints/N2_7_weights.best.Xception.hdf5', verbose=1, save_best_only=True)\n",
    "Xception_model.fit(train_Xception, train_targets, validation_data=(valid_Xception, valid_targets), epochs=20, batch_size=100, callbacks=[checkpointer], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85.4067%\n"
     ]
    }
   ],
   "source": [
    "Xception_model.load_weights('checkpoints/N2_7_weights.best.Xception.hdf5')\n",
    "Xception_predictions = [np.argmax(Xception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_Xception]\n",
    "test_accuracy = 100*np.sum(np.array(Xception_predictions)==np.argmax(test_targets, axis=1))/len(Xception_predictions)\n",
    "\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single case prediction\n",
    "def extract_Xception(tensor):\n",
    "    from keras.applications.xception import Xception, preprocess_input\n",
    "    return Xception(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "def Xception_predict_breed(img_path):\n",
    "    bottleneck_feature = extract_Xception(path_to_tensor(img_path))\n",
    "    predicted_vector = Xception_model.predict(bottleneck_feature)\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Dog! Your breed is likely...\n",
      "rain\\030.Border_terrier\n"
     ]
    }
   ],
   "source": [
    "# dog detector\n",
    "def my_detector(img_path):\n",
    "    if dog_detector(img_path)>0:\n",
    "        print(\"Hello, Dog! Your breed is likely...\")\n",
    "        print(Xception_predict_breed(img_path))\n",
    "    elif face_detector(img_path)>0:\n",
    "        print(\"Hello, Human! You look like a ...\")\n",
    "        print(Xception_predict_breed(img_path))\n",
    "    else:\n",
    "        print(\"Error, not human or dog\")\n",
    "\n",
    "my_detector('../ClassSampleData/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
